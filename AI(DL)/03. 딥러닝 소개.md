# Introduction to Deep Learning

## Deep Learning이란 무엇인가?

deep: 층이 깊다. 많다.

예시로 

데이터 (고양이 또는 개 사진)가 층층이 처리가 되면서 우리가 원하는 output (고양이 또는 개) 에 가까워지는 것을 말한다.

## Learning이란 무엇인가?: 파블로프의 개 예제

learning: 층 사이에 연결되어 있는 시냅스를 학습시키는 것이다. 시냅스의 강도를 조절하는 것이다.

1. 개에게 먹이를 주면 침을 흘린다: 이건 생물학적으로 먹이 인식 뉴런이 활성화 된다. 먹이 인식 뉴런과 침 분비 뉴런은 시냅스로 연결되어 있는데, 이 시냅스가 활성되어 있기 때문에 신호가 전달되어 침분비 뉴런에서도 신호가 발생한다.

2. 개에게 종소리를 울리면 아무 반응이 없다. 벨소리 인식 뉴런이 활성화되지만 벨소리 인식 뉴런과 침 분비 뉴런이 연결된 시냅스는 비활성되어 있기 때문에 침 분비 뉴런으로 신호가 전달되지 않아 침 분비 뉴런은 활성화되지 않는다.

3. 개에게 종소리를 울리고 먹이를 같이 주면 침을 흘린다: 벨소리 뉴런에서 발생한 신호가 시냅스를 거쳐 침 뉴런을 활성화 시킨다. 그리고 벨소리 뉴런도 활성화된다. 생물학적 이론 중 시냅스 앞뒤에 동시에 활성화되면 시냅스의 연결 강도가 증가한다는 이론이 있다. (STDP)  벨소리 뉴런과 침분비 뉴런이 동시에 활성화되어서 두 뉴런을 연결하는 시냅스를 활성화 시킨다. 연결 강도를 높인다는 뜻이다. (학습의 부분)

4. 개에게 종소리를 울리면 침을 흘린다: 벨소리 인식 뉴런이 활성화된다. 벨소리 인식 뉴런과 침 분비 뉴런 사이의 시냅스가 활성먹이 인식 뉴런이 활성되어 있기에 신호가 전달되어 침분비 뉴런에서도 신호가 발생한다.

결론: Bell – Salivation 사이의 시냅스 활성화 = 개를 종소리만 듣고도 침을 분비하게 학습

----

**신경망을 학습한다는 것 = 시냅스의 강도를 조절하여 원하는 출력을 얻게 만든다는 것**

얼굴 인식을 위한 네트워크에서는 인공 심층 신경망의 (뉴런 사이의) 시냅스 강도를 조절하여 얼굴 인식 기능을 수행하도록 학습

## 어떻게 학습할까?

- **Supervised learning (prediction), 지도 학습**
  
  - learning a function that maps an input to an output based on example input-output pairs (labels)
  
  - 대부분의 deep learning의 경우 사용함.

- **Unsupervised learning (understanding의 영역), 비지도 학습** 
  
  - a type of algorithm that learns patterns from unlabeled data
  
  - 선생님이 없어도 학습할 수 있는 상황에서 사용함.
  
  - 데이터의 패턴을 찾아내는 과정임.

- **Reinforcement learning, 강화 학습**
  
  - DNN을 훈련시키는데에는 거의 사용되지 않음.
  
  - 일련의 행동 (action)들을 학습시키는 것이다.
  
  - 어떻게 행동해야 원하는 goal을 얻을 수 있을까? 에 대해 탐구하는 분야이다. (대표적 예시, 바둑)

## Rule-Based Systems

인간이 직접 알고리즘을 디자인 하는 전통적인 방식

```
if (얼굴뾰족)
    return cat
else
    return dog
```

많은 variation, uncentain

![image](https://user-images.githubusercontent.com/68107000/163991352-f0b17f06-c119-475f-9d79-bff98fed0cec.png)

## Classical Machine Learning

![image](https://user-images.githubusercontent.com/68107000/164107922-ac746041-a4ca-4834-bcec-b3158758d3ce.png)

인간이 설계한 알고리즘으로 입력에서 feature (특징) 추출
특징은 인간이 추출 → 특징의 분포를 기계가 학습하여 결과 판단 

**feature**

input을 대표할 수 있는 중요한 정보

**feature의 예시**

- 개와 고양이 구별하기
  
  - 털길이, 얼굴이 뾰족한 정도

- Computer vision
  
  - Edges, vertices, objects, texture, etc

- Character recognition 
  
  - \# of white pixels, # of holes, strokes,  etc

- Speech recognition 
  
  - Length of sounds, similarities in patterns, etc

## Deep Learning

![image](https://user-images.githubusercontent.com/68107000/163991699-26b9c8e6-ae37-4e96-a591-d3ebf639bd2d.png)

**특징 추출** 부터 분포 파악까지 모두 기계가 학습한다.

특징 추출 자체가 DL이고 이걸 기계가 하는 게 DL이다.

deep layer를 지날수록 low-level features 가 high-level feartures 로 점점 abstraction 되어간다. (low와 high는 추상화 정도를 의미한다.) 최고로 추상화된 feature로 구분하게 된다.

실제 biological system도 비슷하게 동작한다고 한다. 결과론적인 이야기이다. (컴퓨터가 학습하게 했더니 생물과 유사한 구조를 가지게 되어 신기하다.)

### 왜 딥러닝이 뜨고 있을까?

![image](https://user-images.githubusercontent.com/68107000/164109735-b17647cd-9df6-401a-b7a9-38b9133bcc8c.png)

NN는 데이터가 많을수록 정확도가 증가한다. large NN은 더 깊은 네트워크를 뜻한다.

하지만 classical ML (인간이 특징을 추출하고 구분만 기계가 하는 학습)은 데이터를 많이 필요로 하지 않는다. 어느 선에서 머무른다.

Rule-based는 데이터의 양과 관계 없이 특정 acc에 고정적인 값을 낸다. NN에 비해 매우 낮다.

### 딥러닝 모델 종류

- Fully-Connected Networks (FCN, MLP)

- Convolutional Neural Networks (CNN)

- Recurrent Neural Networks (RNN)

- Long/Short Term Memory (LSTM)

- Transformers

- **Generative** Adversarial Network (GAN)
  
  - 새로운 데이터를 생성해내는 네트워크. 앞선 네트워크는 모두 구분하는 역할을 함.
