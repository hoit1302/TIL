# Meta Learning

- learning to learn 으로 표현한다. 학습을 위한 학습이라고 표현한다.

- 한 가지 task에 대해서가 아니라 여러 가지 task에 대해서 일반화될 수 있는 모델을 학습한다.

- 그래서 **unseen task**, 보지 못한 task에 대해서도 일반화가 가능해진다.
  
  - 학습하지 않은 것 조차도 학습이 가능해진다.
  
  - **기계가 아는지 모르는지 구분이 가능해진다.**

전통적인 딥러닝에서는 기계가 다 알고 있다는 가정에서 출발한다. 개/고양이 구분 모델은 새로운 이미지에 대해서 무조건 개나 고양이일 것이라고 가정하고 분류한다. 하지만 만약 개미가 들어왔다면 기계는 개 또는 고양이라고 답을 낼 것이다.

기계가 모른다고 구분할 수 있도록 한다.

## 이게 왜 필요할까?

- 실세계에서는 dataset sample이 부족하다.
  
  - 메타 학습은 적은 데이터 수만으로도 generalization이 가능한 학습법이다.

- 학습하는데 시간이 오래걸리는데, 일반적으로 대부분 computation power가 부족하다.
  
  - 그래서 메타 러닝이 뜨고 있다.

## meta learning의 기본적인 흐름을 이해해보자

예를 들어 아이가 동물원에 갔을 때 새로운 동물을 보고 모른다고 인지하고 있다. 여러 장의 동물  카드를 보여주면 인간은 쉽게 한 장의 카드만으로도 수달과 가장 유사한 동물이라서 수달임을 알 수 있게 된다.

보지 못한 input은 (== query)라고 말한다.

적은 수의 데이터만으로도 학습이 가능하다.

그 근본에는 아이가 수달임을 몰랐기 때문에 학습이 가능했던 것이다.

이 과정을 메타 러닝이라고 한다.

## Few-Shot Learning

Few-Shot Learning은 meta learning의 한 종류이다.

적은 수의 sample로 가장 좋은 답변을 찾도록 해준다.

![image](https://user-images.githubusercontent.com/68107000/172830553-a6815517-24e9-47fa-b1a1-1a5a9361e322.png)

인간은 pangolin이 비늘이 동그랗고 귀가 없다는 특징으로 각 2개의 사진만으로도 query의 답을 알 수 있다. 하지만 전통적인 딥러닝으로는 불가능하다. 데이터셋이 너무 적기 때문이다.

![image](https://user-images.githubusercontent.com/68107000/172830706-4e96f405-10ce-4d71-b605-fc8c2db5d69a.png)

training set: learn to learn

1. training set의 목표는 각 image가 허스키다. 코끼리다, 호랑이다 라고 구분하기보다는 어떻게 **서로 다른 class인지를 알게끔, 구분하게끔 학습**을 하는 것이다.

2. 그러면 query image가 들어올 때 기존 class에 없는 rabbit은 "**새로운**" class임을 알 수 있다. 기계가 아는 것과 모르는 것을 구분할 수 있게 된다.

3. 모를 때 **support set**이 주어지는데 query sample은 **토끼와 가장 유사**하기 때문에 토끼임을 알 수 있게 된다. 토끼 이미지가 단 한 장임에도 불구하고 말이다.

## 𝑘-way 𝑛-shot Support Set

![image](https://user-images.githubusercontent.com/68107000/172830831-b003faaf-e190-4650-ade2-008339ade6ae.png)

k-way: support set이 k 클래스를 가지고 있음

n-shot: support set의 모든  class가 n개의 샘플을 가지고 있음

각 숫자는 prediction accuracy에 영향을 준다.

- way 수가 많아지면 (query와 비교해보아야 할 종류 수) accuracy가 떨어지고

- shot 수가 많아지면 (각 class 별 샘플 이미지 수) accuracy가 증가한다.

## Supervised Learning vs. Few-Shot Learning

기존의, 전통적인 supervised-learning은

- 각 class마다 천 개 이상의 데이터셋이 존재한다.

- **test sample**은 training sample에서 보지 못했지만 class는 이미 알고 있는 것이다.

few-shot learning은

- 마찬가지로 **query sample**은 본 적이 없지만

- 훈련된 클래스와는 다른, 모르는 클래스인 샘플이 들어온다.

## Few-Shot Learning은 어떻게 이루어질까?

similarity function: sim(x, x')을 학습하게 된다. training set에서 학습하게 된다.

![image](https://user-images.githubusercontent.com/68107000/172830917-2753ccf3-8b39-4da2-ba0b-abb9c40913ff.png)

이상적으로

- sim(1, 2) = 1

- sim(1, 3) = 0

- sim(2, 3) = 0이 되게 하고 싶다.

이 similarity function은 큰 학습 데이터셋으로 얻을 수 있다. 각각의 class가 정해져 있기 때문에 이미지가 조금 다르더라도 같은 토끼라는 class라면 비슷하도록 학습한다.![image](https://user-images.githubusercontent.com/68107000/172831047-8eadb1d3-4983-452c-8ca6-3feddb53cde7.png)

similarity function을 얻었으면 **prediction**을 위해서 사용하면 된다.

예를 들어 수달이라는 이미지가 query로 들어왔다. 이게 뭔지 알고 싶다. support set (6way 1-shot)의 모든 샘플과 query 이미지를 비교한다. similarity function을 활용해 sample 중에서 가장 similarity score가 높은 동물을 찾는다. 1개의 dataset만으로도 수달임을 알 수 있다.

## Transfer Learning

전이 학습

source task에서 knowledge를 추출해서 target task로 전달해준다.

전통적인 머신러닝은 각 task를 위해 learning 했었다.

2가지 task에 대해서 learning 하고 knowledge를 전달해서 새로운 task에 대해서 learning을 할 수 있도록 한다.

데이터셋이 부족하기 때문에

새로운 task가 들어왔을 때, 데이터셋이 label이 되어있지 않거나 데이터셋이 부족하다면 전통적인 머신러닝은 아예 학습을 할 수 없지만 전이 학습을 이용하면 학습시킬 수 있다.

## Transfer Learning: Definition

**domain**: 𝒟 = {𝒳, 𝑃(𝑋)}

- feature space 𝒳

- marginal distribution 𝑃(𝑋)

**task**: 𝒯 = {𝒴, 𝑃(𝑌|𝑋)}

- label space 𝒴

- conditional distribution 𝑃(𝑌|𝑋): 주어진 feature 𝒳에 대해서 어떤 class에 속하는지 𝑌

다음과 같이 주어져 있다.

- 𝒟_𝑆: source domain

- 𝒟_𝑇: source domain의 learning task

- 𝒯_𝑆: target domain

- 𝒯_𝑇: target domain의 learning task

target predictive function 𝑓\_𝑇()을 학습시키고 싶다.

학습을 위해 𝒟\_𝑆 and 𝒯\_𝑆의 지식을 사용하는데, 𝒟\_𝑆 ≠ 𝒟\_𝑇, or 𝒯\_𝑆 ≠ 𝒯\_𝑇로 다르다.

## Transfer Learning: 다양한 종류

![image](https://user-images.githubusercontent.com/68107000/172779134-90354fab-fb1a-4cda-ab43-2a0286cb19e7.png)

## Fine-Tuning Method

convolution layer를 거쳐 low level feature에서 high level의 feature로 점점 추상화되는데 그래서 feature extractor, 특징점 추출기로 볼 수 있다.

큰 데이터셋으로 pre-train된 source 모델은 generalized가 잘 되어 있다. 이것을 좋은 feature extractor라고 이야기할 수도 있고, 좋은 parameter initialization이라고도 할 수 있다.

![image](https://user-images.githubusercontent.com/68107000/172831786-b854a325-0bc8-4e4b-88ad-08f1d4eea7c3.png)

예를 들어 1. ImageNet은 pre-trained 모델이고 같은 2. 아키텍쳐를 가지는 얼굴 인식 모델을 얻고 싶다면 얼굴 인식 모델에 weight를 전이해주고 3. 기반으로 얼굴 인식을 위한 fine-tuning을 진행하면 된다.

특징점 추출하는 방법은 ImageNet 큰 데이터셋에 의해 배웠고, 그걸 토대로 조금만 학습하면 얼굴 인식을 쉽게 할 수 있게 된다.

overfitting을 방지하기 위해서 convolutional layer는 freeze 시키고 나머지에 대해서만 조금 학습시킨다.

이런 방식은 pre-trained을 통해 얻은 feature나 parameter가 얼굴 인식 모델(target task)에서도 유용할 것이라는 가정을 통해서 이뤄질 수 있다.

## Knowledge Distillation

target model이 source model을 흉내내도록 만든다. 즉, output(feature)을 비슷하게 만든다.

domain이 같고, task도 같을 때 수행한다.

왜 만들까? 

- 일반적으로 target model은 조금 더 작은 모델로 만들게 된다. 작은 모델만으로도 큰 모델처럼 task를 수행해줄 수 있다. model compression(경량화)이 가능해진다.

- scratch learning 보다 좋은 성능을 보인다.

![image](https://user-images.githubusercontent.com/68107000/172831558-e98efeb2-d0de-4a6c-b370-59048ef27ece.png)

domain X가 같고

source (teacher) model - 큼

target (student) model - 작음

output이 똑같도록 학습

teacher network의 knowledge를 distillation 하는 방식으로 student network의 학습을 향상시킬 수 있다.

학습을 어떻게 해줄 것인가에 대한 정의는 loss term에서 정의가 된다. original loss term에서 추가적으로 source와 target output이 유사하도록 만들 수 있는 loss term을 define하면 2개의 network가 같은 output을 낼 수 있도록 학습된다.

## Domain Adaptation (Transductive)

domain은 다르지만 task가 같은 경우이다.

다른 2개의 domain 모두에 대해서 generalize 할 수 있는 feature을 학습시킨다. 그래서 target model이 잘 동작하도록 한다.

target domain의 데이터셋이 충분한 label을 가지고 있지 않을 때 수행한다.

domain invariant feature를 수행해서 source model’s representations이 target domain에서 사용될 수 있다.

source와 target domain input을 모두 수용할 수 있는 representation을 학습하고 source domain과 유사한 target representation을 학습을 하면 domain adaptation이 가능해진다.

![image](https://user-images.githubusercontent.com/68107000/172831295-86f7e083-891d-496c-898e-f76206bf73d9.png)

target domain은 label되어 있지 않아 각 그림이 어떤 숫자를 의미하는지 모를 때

domain invarient한 feature를 잘 학습해서 (source domain에서 각 그림의 숫자를 target domain에게 알려주면 == domain adaptation 해주면) 

target domain도 숫자를 분류할 수 있게 된다.

## Inductive/Unsupervised

이 두 가지는 task가 다른 경우이다. predict할 label이 다른 것을 말한다.

feature extractor와 output layer가 새로운 task에 맞도록 조정되어야 한다.

**Inductive**

![image](https://user-images.githubusercontent.com/68107000/172831402-134ee3c9-c872-4268-a436-a53b76d988e1.png)

같은 사람 얼굴의 domain에서 source task는 나이를 측정하고 target task는 person recognition을 수행한다.

이 경우에는 Multi-task learning/fine-tuning을 사용해 새로운 task에 대해서 잘 동작하도록 한다.

**Unsupervised**

![image](https://user-images.githubusercontent.com/68107000/172831467-7c914369-5399-4420-a19d-22fcac16a5a8.png)

domain 조차 다르다.

## Summary

meta learning의 한 종류로 few-shot learning을 배웠습니다. 적은 이미지 가지고 새로운 것이 어떤 클래스에 속하는지 알 수 있게 되었다.

transfer learning 은 source model로부터 target model로 knowledge를 전달

전달하는 이유는

- Fine-tuning: 데이터셋이 부족한 경우

- Knowledge distillation: model을 경량화하기 위해

- Domain adaptation: 한 도메인의 데이터가 부족한 경우

- Inductive/unsupervised: 다른 task를 수행하기 위해서
