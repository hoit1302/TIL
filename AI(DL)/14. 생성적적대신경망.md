# GAN

Generative Adversarial Network

## Generative Models

이제껏 배운 Single perceptron, Multi-layer perceptron, Deep neural network, Convolutional neural network, Recurrent neural network는 잘 구분하는데 사용하는 모델이다. discriminative model이다.

### Discriminative Model

- 여러 종류의 데이터 인스턴스를 구별

- p(Y|X): X input이 주어졌을 때 Y의 확률 분포로, 조건부 확률 분포

- data space에서 경계선 그리기

### Generative Model

- 새로운 데이터 인스턴스를 생성

- p(X, Y): input과 output을 독립적으로 보고 그 사이의 관계를 캡쳐하는 결합 확률 or p(X): X 자체를 캡쳐

- 데이터가 공간 상에서 어떻게 분포되느냐를 모델링하기

- GAN은 generative model 중 한 가지 모델

- e.g: monet 풍의 그림을 사진으로, 사진을 monet 풍의 그림으로 변환하기, 여름 풍경 사진을 겨울로, 겨울 사진을 여름으로 변환하기, 사람의 피부색, 머리색 바꿔보기, 사람의 표정 바꿔보기, 공학적인 응용도 가능한데, design target(회로 모양을 새기기 위한 판)으로 wafer(실리콘 기판)에 어떻게 세겨질지 예측하기

## GAN

### Key Idea of GAN: Police-Criminal Analogy

범죄자와 경찰이 적대적 경쟁 관계에 있다.

criminal (Generator)은 위조 지폐를 만들어 경찰을 속이려고 한다.

police (discriminator)은 진짜와 가짜의 지폐를 구별하려고 한다.

### Overview

GAN이란 특정한 모양을 가진 network architecture는 아니다. 

DNN을 사용해 적대적 경쟁 관계를 네트워크로 형성한 것 자체를 GAN을 말한다.

![image](https://user-images.githubusercontent.com/68107000/172033644-21829686-da5d-45da-9fdb-02959bb94367.png)

random noise z를 input으로 하여 이미지를 만든다.

Generator network와 Discriminator network는 모두 DNN이다.

Discriminator network 는 실제 사진인지 가짜 사진인지 구멸하기 위해 CNN을 활용한다.

만약 photo → monet 인 GAN을 구축한다면, random noise가 아닌 photo가 input z가 되겠다.

### Training

![image](https://user-images.githubusercontent.com/68107000/172033977-b267c678-04dd-4a57-8309-63dd890d11c5.png)

작아지고 싶어하는 Generator와 커지고 싶어하는 Discriminator인 이 2명의 플레이어가 게임을 하고 있다.

discriminator output은 (0, 1) 값으로 real image의 가능성을 나타낸다.

**Discriminator** 입장에서는

- value function을 최대화하여 real image는 real로 잘 구분하고 fake image는 fake로 잘 구분하고 싶어 한다.

- training data에 대해서는 log D(x) 값을 크게 해 real image로 판별하게 한다.

- noise input에 대해서는  D(G(z)) (G 네트워크를 거쳐 D로 왔을 때) 값을 작게 해 fake image로 판별하게 학습한다.

**Generator** 입장에서는 

- fake image를 잘 구분해내지 못하게 하고 싶다.

- noise input에 대해서 fake image이지만 real image로 인식하기 원하기 때문에, D(G(z)) 값을 1에 가깝도록 높일 수 있게 학습시킨다.

### 문제점

![](C:\Users\Jueun\AppData\Roaming\marktext\images\2022-06-05-12-43-13-image.png)

 앞서 배워오면서 loss function을 minimize하기 위해서 gradient descent를 썼다.

쉽게 생각해 value function을 maximize 하고 싶을 땐 gradient ascent를 사용하면 된다.

위에 적힌 식이 개념적으로는 맞으나 잘 작동하지 않는다. 

2번의 상황을 자세히 살펴보자

함수 그래프를 보면 training 초반 기울기가 작다.

자연스럽게도 원래 판별은 잘하고 생성을 잘 못한다.

discriminator가 맞을 확률을 최소화하는 방식으로 학습하는데 이미 잘하고 있으므로 배울 것이 별로 없다. 학습이 잘 일어나지 않아 gradient가 작다.

### 실제로 잘 쓰이는 Training

![image](https://user-images.githubusercontent.com/68107000/172034296-54b196bd-8a48-48dd-92b1-709a84a4a954.png)

수식 log(1-x)을 log(x)바꾸고 maximize 문제로 바꾸어 ascent를 적용해보았다.

함수 모양을 보면 초반에 가파르게 학습하는 것을 알 수 있다.

2번의 상황을 더 자세히 다시 살펴보면

원래 잘하는 경찰에 잘못 구분하게 학습시킨다. 이말은 즉슨 위조 지폐를 잘 만들도록 많이 학습된다는 뜻이다.

학습이 많이 일어나고 gradient가 크다.

### 다 합쳐서 정리한, GAN Training Algorithm

논문에서 설명하는 GAN이다.

![image](https://user-images.githubusercontent.com/68107000/172034412-ba7b2578-7e9f-4ef2-9b1f-7716f66a7a5a.png)
