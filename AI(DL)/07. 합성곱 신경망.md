# Convolutional Neural Network

## Fully Connected Layer

![image](https://user-images.githubusercontent.com/68107000/164577317-db6572c3-3821-46a4-96f5-4ed0263fe750.png)

## Convolutional Neural Network

- 이미지(2D spatial data) 인식과 분류에 좋음

- not FC → less weights, less computation

- FC보다 효과적으로 feature extraction

## ImageNet Competition

- ImageNet(데이터셋 이름) Large Scale Visual Recognition Challenge (ILSVRC)

- ~14 million images, 1000개의 classes

- top 5 error (5개 상위 class에 있으면 O)

- CNNs made a big breakthrough in the challenge

## 2D Convolution

- input image, input activation, input feature map

- convolution operator

- Filter, Kernel, Weight

- Output image, Output activation, Output feature map

![image](https://user-images.githubusercontent.com/68107000/164578901-0a684b21-ec2a-4ad7-b1e0-2b32cc7e21dc.png)

## Zero Pad

![image](https://user-images.githubusercontent.com/68107000/164579693-565d826e-9124-46a8-be55-a7bd628917e1.png)

size를 유지시켜주기 위한 기법

관행적으로 가장자리에 zero pad를 하는 건 흔하다.

## Interpretation(이해) of Convolution

### edge 찾기

![image](https://user-images.githubusercontent.com/68107000/164580670-4b690639-705c-4159-8eb2-9adad14995c8.png)

- 다양한 convolution kernel 중에 위와 같은 커널은 edge detector의 역할을 한다. 

- edge feature를 extract하는 역할을 한다.

- convolution kernel과 비슷한 양상을 가지는 input pixel은 더 큰 반응을 보인다. 값이 커서 흰색으로 보인다. 변화량 있는 부분은 edge에 해당한다.
  
  ```
  코 부분
  1 1 0   -1 -1 -1
  1 1 0 * -1  8 -1 = (-1) * 5 + 8 = 3
  1 1 0   -1 -1 -1
  ```

- 변화가 없는 곳(edge아님)은 반응이 거의 없다. 값이 작아서 검은색으로 보인다.
  
  ```
  배경 부분
  1 1 1   -1 -1 -1
  1 1 1 * -1  8 -1 = (-1) * 8 + 8 = 0
  1 1 1   -1 -1 -1
  ```

### face 찾기

![image](https://user-images.githubusercontent.com/68107000/164580771-acd1661f-14e6-4a94-ba5d-cbd264c685ba.png)

- filter가 얼굴을 180° 회전한 모습이다. (눈코를 찾을 수 있도록 수학적으로 정밀히 산출된 필터임)

- 눈코와 비슷하면 cross-correlate(상호 비교) ↑ → output ↑ (하얗게 표시! 점같은 부분)

- 비슷하지 않으면 cross-correlate(상호 비교) ↓ → output ↓ (까맣게 표시)

---

과거 computer vision은 conv kernel (eg. edge detector filter, face detector)을 사람이 찾았다. 

지금은 커널을 기계가 찾아준다!

## 3D Convolution

실제로는 3D conv를 더 많이 쓴다.

![image](https://user-images.githubusercontent.com/68107000/164582986-0755ec31-5df7-4f40-86c8-ac158416c292.png)

- 3D input feature map (H1 * W1 * input channel(depth))

- 3D filter (F * F * input channel(depth))

- 2D output feature map (H2* W2)

각 2차원끼리(채널) 곱하고 덧셈한 것을 쾅 찍었다! (합했다!) 이동하면서 같은 행동을 한다.

## Output channel

실제 cnn에서는 output channel이라는 한가지 dimension이 더 생긴다. input feature map 뿐만아니라 output feature map도 3D로 만든다. 그러면 filter는 4D가 된다. 아래의 구조가 일반적인 convolution layer의 구조가 된다.

![image](https://user-images.githubusercontent.com/68107000/164623268-c7b2b0cf-352a-4821-83c5-998feefbb203.png)

- 3D input feature map (H1 * W1 * input channels (혹은 depth))

- 4D filter (F * F * input channel(depth), K)

- 3D output feature map (H2* W2 * Output channels(혹은 depth) == K)

(나만의 기억법) 각 2차원끼리 곱하고 더한 것을 쾅 쾅 쾅 (3D 필터의 개수만큼 == K 내려가면서) 그리고 같은 행동을 이동하면서.

## Convolutional Layer 요약

![image](https://user-images.githubusercontent.com/68107000/164623459-bbe9f33d-118d-4874-ba62-15b2531b8e44.png)

bias는 3D filter에 하나씩 존재

## Convolutional Layer in terms of Neurons

**Receptive field**

![image](https://user-images.githubusercontent.com/68107000/164624109-5f3834d9-a56d-440a-af86-64f75f5692d2.png)

## vs. Biological Observation

retina 망막에서 receptive field라는 영역 단위로 빛 신호를 처리한다. 그리고 망막 세포들이 hierarchical하게 존재해서 각 receptive field가 담당하고 그 뒤에 층의 세포에게 신호를 넘겨주는데 앞쪽 simple cells는 방향만 감지하고 점점 뒤로 갈수록 complex cells들은 복잡하게 방향과 움직임을 인식하고 hypercomplex cell들은 꼭짓점이 있는 movement를 인식한다.

## Pooling (Subsampling)

non-linear down-sampling의 형식이기 때문에 subsampling 이라고도 부른다.

- 장점
  
  - Feature map size reduction
    
    - 연산량 ↓, 용량 ↓
    
    - 2 ⨉ 2 maxpooling with stride 2 하면 feature size가 ½ ⨉ ½ 씩 줄어듦.
  
  - translation invariance에 강해진다.
    
    - 이미지에 사물이 존재할 때 조금 움직여도 같은 사물로 인식

## AlexNet

network architecture diagram

![image](https://user-images.githubusercontent.com/68107000/164644610-516ae0ad-44a2-4b85-97c9-dab2f8052150.png)

- 왜 input channel이 3인가? RGB 라서 3

- 첫번째 CONV layer의 weight 개수는 `F^2 * K * C` = 11^2 * 96 * 3

- 첫번째 CONV layer를 거친 후 `W2` = `(W1 - F + 2P) / S + 1` = (224 - 11 + 3) / 4 + 1 = 55

- 두번째 CONV 수행하고 ReLU activation function을 거친 뒤 3 ⨉ 3 maxpooling with stride 2 를 수행해서 55 → 27 거의 반절로 줄었다.
  
  - 27 = (55 - 3) / 2 + 1

- 두번째 CONV layer weight의 개수: 5^2 * 96 * 256

- 세번째 CONV layer weight의 개수: 3^2 * 256 * 384

- 네번째 CONV layer weight의 개수: 3^2 * 384 * 384

- 다섯번째 CONV layer weight의 개수: 5^5 * 384 * 256

- 첫번째 Dense layer의 weight 개수: 7^2 * 256 * 4096
  
  - 13 ⨉ 13 에서 max pooling을 통해 7 ⨉ 7이 되었기 때문

- 두번째 Dense layer의 weight 개수: 4096 * 4096

- 세번째(마지막) Dense layer의 weight 개수: 4096 * 1000
  
  - 마지막 수는 ImageNet dataset class가 1000개라서

filter와의 conv 연산 자체가 feature extraction에 해당한다.

## 어디에든 있는 CNN

### AlphaGo

- interpret Go status

- google (자체) TPU chip 설계

- 그냥 추가로
  
  - policy network: 다음 수에 대한 예측
  
  - value network: 판세 판별

### Tesla's Autopilot

- front scene recognition을 위해

- 전방 주시 카메라가 사물 인식함.

- 실시간이 중요함.

- 자체 개발 chip

- NPU (neural processing unit): 딥러닝 전용 가속 HW

### Apple Face ID

- 얼굴 인식

- 빠르게 동작시키기 위해 A14 Bionic (NPU)이나 M1 같은 chip 내장

### Samsung Galaxy S21

- photo enhancement

- 스마트폰 전용칩 Exynos 9(9820) 안에 NPU 존재

🙌🏻 많은 양의 연산을 요구하기 시작했다. HW도 잘 알고 있는 SW 개발자가 되자.
